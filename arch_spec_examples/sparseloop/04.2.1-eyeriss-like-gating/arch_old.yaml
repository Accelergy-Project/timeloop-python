architecture:
  version: 0.4
  subtree:
    - name: eyeriss_168
      attributes:
        technology: -1
      local:
        - name: DRAM
          class: DRAM
          required_actions: [read, write, update, leak]
          attributes:
            technology: -1
            width: 64
            block_size: 4
            datawidth: 16
            metadata_storage_width: 60
            metadata_datawidth: 5
            metadata_block_size: 12

        - name: shared_glb
          class: storage
          subclass: smartbuffer_metadata
          required_actions: [read, write, update, leak]
          attributes:
            technology: -1
            data_storage_depth: 12800
            data_storage_width: 64
            block_size: 4
            n_banks: 1
            read_bandwidth: 16
            write_bandwidth: 16
            metadata_storage_depth: 0
            metadata_storage_width: 0
            metadata_block_size: 1
            metadata_datawidth: 0
            metadata_counter_width: 9
            # Note that the two diretives below are describing 
            # whether this level can compress and decompress data transfers
            # from itself to its parent (not child)
            decompression_supported: true  # from DRAM decompression
            compression_supported: true    # to DRAM compression

        - name: DummyBuffer[0..13]
          class: storage
          subclass: SRAM
          required_actions: [read, write, update, leak]
          attributes:
            technology: -1
            width: 16
            depth: 0
            num_banks: 1
            datawidth: 16
            entries: 0
            meshX: 14

      subtree:
        - name: PE[0..167]
          local:
            - name: ifmap_spad
              class: storage
              subclass: smartbuffer
              required_actions: [read, write, update, leak]
              attributes:
                technology: -1
                data_storage_depth: 12
                data_storage_width: 17 # actual data + 1bit mask
                n_banks: 1
                datawidth: 17
                read_bandwidth: 2
                write_bandwidth: 2
                meshX: 14

            - name: weights_spad
              class: storage
              subclass: smartbuffer
              required_actions: [read, write, update, leak]
              attributes:
                technology: -1
                data_storage_depth: 224
                data_storage_width: 16
                n_banks: 1
                datawidth: 16
                read_bandwidth: 2
                write_bandwidth: 2
                meshX: 14


            - name: psum_spad
              class: storage
              subclass: smartbuffer
              required_actions: [read, write, update, leak]
              attributes:
                technology: -1
                data_storage_depth: 24
                data_storage_width: 16
                n_banks: 1
                datawidth: 16
                meshX: 14

            - name: MACs
              class: compute
              subclass: mac
              attributes:
                technology: -1
                meshX: 14
                datawidth: 16


# eyeriss v1 optimization features
#  - DRAM compression for Inputs and Weights
#    - for each tile sent from DRAM to GLB, the dimensions are flattened together, thus flattened_rankIDs include all dimensions
#    - we carry a top level UOP flag for each compressed GLB tile to indicate the order in which the compressed tile is sent from DRAM
#  - gating on weights scratchpad based on input activation's sparsity
#  - note that the bitmask metadata associated with the ifmap scratchpad is not here because the metadata did not
#    allow ifmap accesses to be saved, which is what conventionally what metadata will help to achieve, so we model
#    it as an extra bit in the datawidth instead of as a metadata
sparse_optimizations:
  version: 0.4
  targets:
    - name: DRAM
      representation_format:
        data_spaces:
          - name: Inputs
            ranks:
              - format: UOP
                flattened_rankIDs: [ [R, S, P, C, M, N, Q] ]
              - format: RLE
                flattened_rankIDs: [ [R, S, P, C, M, N, Q] ]

          - name: Outputs
            ranks:
              - format: UOP
                flattened_rankIDs: [ [P, M, N, Q] ]
              - format: RLE
                flattened_rankIDs: [ [P, M, N, Q] ]

    - name: weights_spad
      action_optimization:
        - type: gating
          options:
            - target: Weights
              condition_on: [ Inputs ]

mapping:
  # certain buffer only stores certain datatypes
  - target: DRAM
    type: temporal
    permutation: RSP CMNQ
    factors: R=1 S=1 P=1 C=64 M=6 N=1 Q=1
  - target: DRAM
    type: bypass
    keep: [Weights, Inputs, Outputs]


  # only allow fanout of M, Q out from glb
  - target: shared_glb
    type: spatial
    split: 7
    permutation: NCPRSQM
    factors: N=1 C=1 P=1 R=1 S=1 Q=0 M=1
  - target: shared_glb
    type: temporal
    permutation: QRSC PNM
    factors: Q=1 R=1 S=1 P=0 C=1 N=4 M=1
  - target: shared_glb
    type: bypass
    bypass: [Weights]
    keep: [Inputs, Outputs]

  # enforce the hardware limit of the bypassing everything
  - target: DummyBuffer
    type: temporal
    factors: N=1 M=1 C=1 P=1 Q=1 R=1 S=1
    permutation: NMCPQRS
  - target: DummyBuffer
    type: bypass
    bypass: [Inputs, Outputs, Weights]
  - target: DummyBuffer
    type: spatial
    split: 4
    permutation: NPQR SCM
    factors: N=1 P=1 Q=1 R=1 S=0 C=1 M=4

  - target: ifmap_spad
    type: bypass
    bypass: [Weights, Outputs]
    keep: [Inputs]
  - target: ifmap_spad
    type: temporal
    permutation: NMCPQRS
    factors: N=1 M=1 C=1 P=1 Q=1 R=1 S=1


  # row stationary -> 1 row at a time
  - target: weights_spad
    type: temporal
    permutation: NMPQS CR
    factors: N=1 M=1 P=1 Q=1 S=1 R=0 C=4
  - target: weights_spad
    type: bypass
    bypass: [Inputs, Outputs]
    keep: [Weights]

  # one ofmap position but of different output channels
  - target: psum_spad
    type: temporal
    permutation: NCPQRS M
    factors: N=1 C=1 R=1 S=1 P=1 Q=1 M=16
  - target: psum_spad
    type: bypass
    bypass: [Inputs, Weights]
    keep: [Outputs]